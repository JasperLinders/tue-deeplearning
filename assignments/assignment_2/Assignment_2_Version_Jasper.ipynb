{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d32f8d18",
      "metadata": {
        "id": "d32f8d18"
      },
      "source": [
        "# Group Details\n",
        "\n",
        "## Group Name: Group 08\n",
        "\n",
        "### Student 1: Jasper Linders\n",
        "\n",
        "### Student 2: Alexander Liu\n",
        "\n",
        "### Student 3: Sjoerd van Straten"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "faec2056",
      "metadata": {
        "id": "faec2056"
      },
      "source": [
        "# Loading Data and Preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "7d0580a5",
      "metadata": {
        "id": "7d0580a5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "mom5nRqivEiR",
      "metadata": {
        "id": "mom5nRqivEiR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "b0756591",
      "metadata": {
        "id": "b0756591"
      },
      "outputs": [],
      "source": [
        "def load_array(filename, task):\n",
        "    datapoint = np.load(filename)\n",
        "    if task == 'task 1':\n",
        "        initial_state = datapoint['initial_state']\n",
        "        terminal_state = datapoint['terminal_state']\n",
        "        return initial_state, terminal_state\n",
        "    elif task == 'task 2' or task == 'task 3':\n",
        "        whole_trajectory = datapoint['trajectory']\n",
        "        # change shape: (num_bodies, attributes, time) ->  num_bodies, time, attributes\n",
        "        whole_trajectory = np.swapaxes(whole_trajectory, 1, 2)\n",
        "        initial_state = whole_trajectory[:, 0]\n",
        "        target = whole_trajectory[:, 1:, 1:]  # drop the first timepoint (second dim) and mass (last dim) for the prediction task\n",
        "        return initial_state, target\n",
        "    else:\n",
        "        raise NotImplementedError(\"'task' argument should be 'task 1', 'task 2' or 'task 3'!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "bb77a4be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb77a4be",
        "outputId": "87b55db3-1db0-4537-98c5-50132690a0da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape of initial state (model input): (8, 5)\n",
            "shape of terminal state (to be predicted by model): (8, 2)\n",
            "The initial x-coordinate of the body with index 2 in this trajectory was -5.159721083543527\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This cell gives an example of loading a datapoint with numpy for task 1.\n",
        "\n",
        "The arrays returned by the function are structures as follows:\n",
        "initial_state: shape (n_bodies, [mass, x, y, v_x, v_y])\n",
        "terminal_state: shape (n_bodies, [x, y])\n",
        "\n",
        "\"\"\"\n",
        "example = load_array('data/task 1/train/trajectory_0.npz', task='task 1')\n",
        "\n",
        "initial_state, terminal_state = example\n",
        "print(f'shape of initial state (model input): {initial_state.shape}')\n",
        "print(f'shape of terminal state (to be predicted by model): {terminal_state.shape}')\n",
        "\n",
        "body_idx = 2\n",
        "print(f'The initial x-coordinate of the body with index {body_idx} in this trajectory was {initial_state[body_idx, 1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "1c3ea4cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c3ea4cb",
        "outputId": "45b5f08e-56ce-4868-eb93-ea22a551f360"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape of initial state (model input): (8, 5)\n",
            "shape of terminal state (to be predicted by model): (8, 49, 4)\n",
            "The y-coordinate of the body with index 2 at time with index 30 in remaining_trajectory was -0.3861544940435097\n",
            "the shape of the input of a test data example is (8, 5)\n",
            "the shape of the target of a test data example is (8, 49, 4)\n",
            "values of the test data example at time 30:\n",
            " [[-5.85725792 -5.394571           nan         nan]\n",
            " [-6.03781257 -5.72445953         nan         nan]\n",
            " [-0.90623054 -6.93416278         nan         nan]\n",
            " [ 2.83149339 -7.50100819         nan         nan]\n",
            " [-2.85586881  1.77667501         nan         nan]\n",
            " [ 4.04424526  4.00563603         nan         nan]\n",
            " [-5.24887713 -4.83081005         nan         nan]\n",
            " [-5.81391023 -5.1109838          nan         nan]]\n",
            "note: velocity values are unobserved (NaNs) in the test data!\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This cell gives an example of loading a datapoint with numpy for task 2 / 3.\n",
        "\n",
        "The arrays returned by the function are structures as follows:\n",
        "initial_state: shape (n_bodies, [mass, x, y, v_x, v_y])\n",
        "remaining_trajectory: shape (n_bodies, time, [x, y, v_x, v_y])\n",
        "\n",
        "Note that for this task, you are asked to evaluate performance only with regard to the predictions of the positions (x and y).\n",
        "If you use the velocity of the remaining trajectory for training,\n",
        "this use should be purely auxiliary for the goal of predicting the positions [x,y] over time.\n",
        "While testing performance of your model on the test set, you do not have access to v_x and v_y of the remaining trajectory.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "example = load_array('data/task 2_3/train/trajectory_0.npz', task='task 2')\n",
        "\n",
        "initial_state, remaining_trajectory = example\n",
        "print(f'shape of initial state (model input): {initial_state.shape}')\n",
        "print(f'shape of terminal state (to be predicted by model): {remaining_trajectory.shape}')\n",
        "\n",
        "body_idx = 2\n",
        "time_idx = 30\n",
        "print(f'The y-coordinate of the body with index {body_idx} at time with index {time_idx} in remaining_trajectory was {remaining_trajectory[body_idx, time_idx, 1]}')\n",
        "\n",
        "test_example = load_array('data/task 2_3/test/trajectory_900.npz', task='task 3')\n",
        "test_initial_state, test_remaining_trajectory = test_example\n",
        "print(f'the shape of the input of a test data example is {test_initial_state.shape}')\n",
        "print(f'the shape of the target of a test data example is {test_remaining_trajectory.shape}')\n",
        "print(f'values of the test data example at time {time_idx}:\\n {test_remaining_trajectory[:, time_idx]}')\n",
        "print('note: velocity values are unobserved (NaNs) in the test data!')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "059b633c",
      "metadata": {
        "id": "059b633c"
      },
      "source": [
        "# Data Handling and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "usUER0gM6OOM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usUER0gM6OOM",
        "outputId": "ff5b16b2-f9eb-498a-9a34-a5032063d39d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([900, 9, 5])\n",
            "torch.Size([900, 9, 2])\n",
            "torch.Size([100, 9, 5])\n",
            "torch.Size([100, 9, 2])\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "\n",
        "class ImportData(Dataset):\n",
        "    def __init__(self, folder_path):\n",
        "        self.folder_path = folder_path\n",
        "        self.file_list = sorted(os.listdir(folder_path))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        file_name = self.file_list[index]\n",
        "        file_path = os.path.join(self.folder_path, file_name)\n",
        "        data, label = load_array(file_path, task='task 1')\n",
        "        return data, label\n",
        "\n",
        "# Create an instance of the custom dataset class with the folder path\n",
        "train_import = ImportData('data/task 1/train/')\n",
        "test_import = ImportData('data/task 1/test/')\n",
        "\n",
        "X_train_import = []\n",
        "y_train_import = []\n",
        "X_test_import = []\n",
        "y_test_import = []\n",
        "\n",
        "# Iterate through the train_dataset to extract data and labels\n",
        "for data, label in train_import:\n",
        "    X_train_import.append(data)\n",
        "    y_train_import.append(label)\n",
        "\n",
        "for data, label in test_import:\n",
        "    X_test_import.append(data)\n",
        "    y_test_import.append(label)\n",
        "\n",
        "max_length = 9\n",
        "\n",
        "# Pad the data samples with zeros to have the same shape\n",
        "X_train_padded = []\n",
        "for data in X_train_import:\n",
        "    pad_width = max_length - data.shape[0]\n",
        "    padded_data = np.pad(data, ((0, pad_width), (0, 0)), mode='constant')\n",
        "    X_train_padded.append(padded_data)\n",
        "\n",
        "y_train_padded = []\n",
        "for label in y_train_import:\n",
        "    pad_width = max_length - label.shape[0]\n",
        "    padded_label = np.pad(label, ((0, pad_width), (0, 0)), mode='constant')\n",
        "    y_train_padded.append(padded_label)\n",
        "\n",
        "X_test_padded = []\n",
        "for data in X_test_import:\n",
        "    pad_width = max_length - data.shape[0]\n",
        "    padded_data = np.pad(data, ((0, pad_width), (0, 0)), mode='constant')\n",
        "    X_test_padded.append(padded_data)\n",
        "\n",
        "y_test_padded = []\n",
        "for label in y_test_import:\n",
        "    pad_width = max_length - label.shape[0]\n",
        "    padded_label = np.pad(label, ((0, pad_width), (0, 0)), mode='constant')\n",
        "    y_test_padded.append(padded_label)\n",
        "\n",
        "# Convert the padded data and labels to tensors\n",
        "X_train = torch.tensor(np.array(X_train_padded))\n",
        "y_train = torch.tensor(np.array(y_train_padded))\n",
        "X_test = torch.tensor(np.array(X_test_padded))\n",
        "y_test = torch.tensor(np.array(y_test_padded))\n",
        "\n",
        "# Print the shape of X_train and the first label in y_train\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "WTW_fnFoefoU",
      "metadata": {
        "id": "WTW_fnFoefoU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Function to process a single data point\n",
        "def create_graph(data_point):\n",
        "\n",
        "    #Create node features\n",
        "    node_features = data_point[:, 1:]  # Exclude the mass column\n",
        "\n",
        "    # Compute edge indices\n",
        "    edge_indices = []\n",
        "    for i in range(9):\n",
        "        for j in range(9):\n",
        "            if i != j:\n",
        "                edge_indices.append([i, j])\n",
        "    edge_indices = torch.tensor(edge_indices).t().contiguous()\n",
        "\n",
        "    # # Compute edge features\n",
        "    # edge_features = []\n",
        "    # for i in range(9):\n",
        "    #     for j in range(9):\n",
        "    #         if i < j:\n",
        "    #             relative_position = node_features[j] - node_features[i]\n",
        "    #             relative_mass = node_features[j, 0] / node_features[i, 0]\n",
        "    #             edge_features.append(torch.cat((torch.tensor([relative_position]), torch.tensor([relative_mass], dtype=torch.float32))))\n",
        "    # edge_features = torch.stack(edge_features)\n",
        "\n",
        "    return node_features, edge_indices #, edge_features\n",
        "\n",
        "node_features, edge_indices = create_graph(initial_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "6f456715",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "         3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "         6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8],\n",
              "        [1, 2, 3, 4, 5, 6, 7, 8, 0, 2, 3, 4, 5, 6, 7, 8, 0, 1, 3, 4, 5, 6, 7, 8,\n",
              "         0, 1, 2, 4, 5, 6, 7, 8, 0, 1, 2, 3, 5, 6, 7, 8, 0, 1, 2, 3, 4, 6, 7, 8,\n",
              "         0, 1, 2, 3, 4, 5, 7, 8, 0, 1, 2, 3, 4, 5, 6, 8, 0, 1, 2, 3, 4, 5, 6, 7]])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "edge_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "f47f92fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "train_graphs_lst = []\n",
        "\n",
        "for graph in zip(X_train, y_train):\n",
        "    train_graphs_lst.append(Data(x=graph[0], edge_index=edge_indices, y=graph[1]))\n",
        "\n",
        "train_dataloader = DataLoader(train_graphs_lst, batch_size=32, shuffle=True)\n",
        "\n",
        "\n",
        "test_graphs_lst = []\n",
        "\n",
        "for graph in zip(X_test, y_test):\n",
        "    train_graphs_lst.append(Data(x=graph[0], edge_index=edge_indices, y=graph[1]))\n",
        "\n",
        "test_dataloader = DataLoader(train_graphs_lst, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "e9b9a698",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FIRST 3 BATCHES IN TRAIN LOADER:\n",
            "________________________________\n",
            "\n",
            "DataBatch(x=[288, 5], edge_index=[2, 2304], y=[288, 2], batch=[288], ptr=[33])\n",
            "Num graphs: 32 \n",
            "\n",
            "DataBatch(x=[288, 5], edge_index=[2, 2304], y=[288, 2], batch=[288], ptr=[33])\n",
            "Num graphs: 32 \n",
            "\n",
            "DataBatch(x=[288, 5], edge_index=[2, 2304], y=[288, 2], batch=[288], ptr=[33])\n",
            "Num graphs: 32 \n",
            "\n",
            ".....\n"
          ]
        }
      ],
      "source": [
        "print('FIRST 3 BATCHES IN TRAIN LOADER:\\n________________________________\\n')\n",
        "\n",
        "cnt = 0\n",
        "for batch in train_dataloader:\n",
        "    if cnt < 3:\n",
        "        print(batch)\n",
        "        print('Num graphs:', batch.num_graphs, '\\n')\n",
        "    cnt += 1\n",
        "\n",
        "print('.....')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "18b2874d",
      "metadata": {
        "id": "18b2874d"
      },
      "source": [
        "# Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "27af78bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch_geometric.nn.conv import GatedGraphConv as GGC\n",
        "\n",
        "from torch.nn import Linear, Parameter\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import add_self_loops, degree\n",
        "\n",
        "\n",
        "class GCNConv(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__(aggr='add')\n",
        "        self.lin = Linear(in_channels, out_channels, bias=False)\n",
        "        self.bias = Parameter(torch.Tensor(out_channels))\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin.reset_parameters()\n",
        "        self.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # x has shape [N, in_channels]\n",
        "        # edge_index has shape [2, E]\n",
        "\n",
        "        # Step 1: Add self-loops to the adjacency matrix.\n",
        "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "\n",
        "        # Step 2: Linearly transform node feature matrix.\n",
        "        x = self.lin(x)\n",
        "\n",
        "        # Step 3: Compute normalization.\n",
        "        row, col = edge_index\n",
        "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "        # Step 4-5: Start propagating messages.\n",
        "        out = self.propagate(edge_index, x=x, norm=norm)\n",
        "\n",
        "        # Step 6: Apply a final bias vector.\n",
        "        out += self.bias\n",
        "\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j, norm):\n",
        "        # x_j has shape [E, out_channels]\n",
        "\n",
        "        # Step 4: Normalize node features.\n",
        "        return norm.view(-1, 1) * x_j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "dd650140",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GCNConv()"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conv = GCNConv(7, 2)\n",
        "conv"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "dea70d73",
      "metadata": {
        "id": "dea70d73"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fd8030d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# '''\n",
        "# Training the GNN\n",
        "# '''\n",
        "# model_gnn = GGCN(out_channels=2, num_layers=5, aggr='add', bias=True) # initialize GNN\n",
        "# print(model_gnn)\n",
        "\n",
        "# # same loss and optimizer as before\n",
        "# loss_func = torch.nn.CrossEntropyLoss()  \n",
        "# optimizer = torch.optim.Adam(model_gnn.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "# def train_gnn():\n",
        "#     model_gnn.train()  # set the model to training 'mode' (i.e., apply dropout)\n",
        "#     optimizer.zero_grad()  # set gradients to 0\n",
        "#     out = model_gnn(train_data.x, train_data.)  # propagate the data through the model\n",
        "#     loss = loss_func(out[train_data.train_mask], data.y[train_data.train_mask])  # compute the loss based on our training mask\n",
        "#     loss.backward()  # derive gradients\n",
        "#     optimizer.step()  # update all parameters based on the gradients\n",
        "#     return loss\n",
        "\n",
        "# def test_gnn(mask):\n",
        "#     model_gnn.eval()  # set the model to evaluation 'mode' (don't use dropout)\n",
        "#     out = model_gnn(data.x, data.edge_index)  # propagate the data through the model\n",
        "#     pred = out.argmax(dim=1)  # as prediction, we take the class with the highest probability\n",
        "#     test_correct = pred[mask] == data.y[mask]  # create a tensor that evaluates whether predictions were correct\n",
        "#     test_acc = int(test_correct.sum()) / int(mask.sum())  # get the accuracy\n",
        "#     return test_acc\n",
        "\n",
        "\n",
        "# train_accs = []\n",
        "# test_accs = []\n",
        "# epochs = 50\n",
        "# for epoch in range(1, epochs+1): \n",
        "#     loss = train_gnn()  # do one training step over the entire dataset\n",
        "#     train_acc = test_gnn(data.train_mask)  # compute the training accuracy\n",
        "#     test_acc = test_gnn(data.test_mask)  # compute the test accuracy\n",
        "#     print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
        "#     train_accs.append(train_acc)  # save accuracies so we can plot them\n",
        "#     test_accs.append(test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "db6f61f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os.path as osp\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "import torch_geometric\n",
        "from torch_geometric.datasets import Planetoid, TUDataset\n",
        "\n",
        "from torch_geometric.nn.inits import uniform\n",
        "from torch.nn import Parameter as Param\n",
        "from torch import Tensor\n",
        "torch.manual_seed(42)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "from torch_geometric.nn.conv import MessagePassing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "7bfdeea9",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hid_dims, out_dim):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.mlp = nn.Sequential()\n",
        "        dims = [input_dim] + hid_dims + [out_dim]\n",
        "        for i in range(len(dims)-1):\n",
        "            self.mlp.add_module('lay_{}'.format(i),nn.Linear(in_features=dims[i], out_features=dims[i+1]))\n",
        "            if i+2 < len(dims):\n",
        "                self.mlp.add_module('act_{}'.format(i), nn.Tanh())\n",
        "    def reset_parameters(self):\n",
        "        for i, l in enumerate(self.mlp):\n",
        "            if type(l) == nn.Linear:\n",
        "                nn.init.xavier_normal_(l.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.mlp(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "f8a4c557",
      "metadata": {},
      "outputs": [],
      "source": [
        "class GatedGraphConv(MessagePassing):\n",
        "    \n",
        "    def __init__(self, out_channels, num_layers, aggr = 'add',\n",
        "                 bias = True, **kwargs):\n",
        "        super(GatedGraphConv, self).__init__(aggr=aggr, **kwargs)\n",
        "\n",
        "        self.out_channels = out_channels\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.weight = Param(Tensor(num_layers, out_channels, out_channels))\n",
        "        self.rnn = torch.nn.GRUCell(out_channels, out_channels, bias=bias)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        uniform(self.out_channels, self.weight)\n",
        "        self.rnn.reset_parameters()\n",
        "\n",
        "    def forward(self, data):\n",
        "        x = data.x\n",
        "        edge_index = data.edge_index\n",
        "        edge_weight = data.edge_attr\n",
        "        if x.size(-1) > self.out_channels:\n",
        "            raise ValueError('The number of input channels is not allowed to '\n",
        "                             'be larger than the number of output channels')\n",
        "\n",
        "        if x.size(-1) < self.out_channels:\n",
        "            zero = x.new_zeros(x.size(0), self.out_channels - x.size(-1))\n",
        "            x = torch.cat([x, zero], dim=1)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            m = torch.matmul(x, self.weight[i])\n",
        "            m = self.propagate(edge_index, x=m, edge_weight=edge_weight,\n",
        "                               size=None)\n",
        "            x = self.rnn(m, x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def message(self, x_j, edge_weight):\n",
        "        return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j\n",
        "\n",
        "    def message_and_aggregate(self, adj_t, x):\n",
        "        return matmul(adj_t, x, reduce=self.aggr)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '{}({}, num_layers={})'.format(self.__class__.__name__,\n",
        "                                              self.out_channels,\n",
        "                                              self.num_layers)\n",
        "\n",
        "class GGNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GGNN, self).__init__()\n",
        "        \n",
        "        self.conv = GatedGraphConv(2, 5)\n",
        "        self.mlp = MLP(5, [32,32,32,32,32], 2)\n",
        "        \n",
        "    def forward(self):\n",
        "        x = self.conv(data)\n",
        "        x = self.mlp(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "62ad6eea",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "dataset = 'Cora'\n",
        "transform = T.Compose([T.TargetIndegree(),\n",
        "])\n",
        "path = osp.join('data', dataset)\n",
        "dataset = Planetoid(path, dataset, transform=transform)\n",
        "data = dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "6b55f6e2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_attr=[10556, 1])"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "6fd97f38",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3, 4, 4, 0, 3, 2, 0, 3, 3, 2, 0, 0, 4, 3, 3, 3, 2, 3, 1, 3, 5, 3, 4, 6,\n",
              "        3, 3, 6, 3, 2, 4, 3, 6, 0, 4, 2, 0, 1, 5, 4, 4, 3, 6, 6, 4, 3, 3, 2, 5,\n",
              "        3, 4, 5, 3, 0, 2, 1, 4, 6, 3, 2, 2, 0, 0, 0, 4, 2, 0, 4, 5, 2, 6, 5, 2,\n",
              "        2, 2, 0, 4, 5, 6, 4, 0, 0, 0, 4, 2, 4, 1, 4, 6, 0, 4, 2, 4, 6, 6, 0, 0,\n",
              "        6, 5, 0, 6, 0, 2, 1, 1, 1, 2, 6, 5, 6, 1, 2, 2, 1, 5, 5, 5, 6, 5, 6, 5,\n",
              "        5, 1, 6, 6, 1, 5, 1, 6, 5, 5, 5, 1, 5, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.y[data.train_mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43f32cf5",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = GGNN().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    loss_fn(model()[data.train_mask], data.y[data.train_mask]).backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    logits, accs = model(), []\n",
        "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "        accs.append(acc)\n",
        "    return accs\n",
        "\n",
        "\n",
        "for epoch in range(1, 51):\n",
        "    train()\n",
        "    accs = test()\n",
        "    train_acc = accs[0]\n",
        "    val_acc = accs[1]\n",
        "    test_acc = accs[2]\n",
        "    print('Epoch: {:03d}, Train Acc: {:.5f}, '\n",
        "          'Val Acc: {:.5f}, Test Acc: {:.5f}'.format(epoch, train_acc,\n",
        "                                                       val_acc, test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c193439d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(train_dataloader):\n",
        "\n",
        "    loss = []\n",
        "    counter = []\n",
        "    iteration_number = 0\n",
        "    \n",
        "    # Iterate over batches\n",
        "    for i, (img0, img1, label) in enumerate(train_dataloader, 0):\n",
        "\n",
        "        # Send the images and labels to CUDA\n",
        "        img0, img1, label = img0.float().cuda(), img1.float().cuda(), label.cuda()\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Pass in the two images into the network and obtain two outputs\n",
        "        output1, output2 = net(img0, img1)\n",
        "\n",
        "        # Pass the outputs of the networks and label into the loss function\n",
        "        loss_contrastive = criterion(output1, output2, label)\n",
        "\n",
        "        # Calculate the backpropagation\n",
        "        loss_contrastive.backward()\n",
        "\n",
        "        # Optimize\n",
        "        optimizer.step()\n",
        "        \n",
        "        loss.append(loss_contrastive.item())\n",
        "    loss = np.array(loss)\n",
        "    return loss.mean()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d5fb3b29",
      "metadata": {
        "id": "d5fb3b29"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf5fa1b4",
      "metadata": {
        "id": "bf5fa1b4"
      },
      "outputs": [],
      "source": [
        "#todo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2280031f",
      "metadata": {
        "id": "2280031f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a8240f1",
      "metadata": {
        "id": "3a8240f1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
