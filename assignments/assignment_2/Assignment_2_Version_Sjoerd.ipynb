{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d32f8d18",
      "metadata": {
        "id": "d32f8d18"
      },
      "source": [
        "# Group Details\n",
        "\n",
        "## Group Name: Group 08\n",
        "\n",
        "### Student 1: Jasper Linders\n",
        "\n",
        "### Student 2: Alexander Liu\n",
        "\n",
        "### Student 3: Sjoerd van Straten"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "faec2056",
      "metadata": {
        "id": "faec2056"
      },
      "source": [
        "# Loading Data and Preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "udTLsaQ9H5Nw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udTLsaQ9H5Nw",
        "outputId": "cf958c62-2000-45af-c592-6954044a5e46"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "7d0580a5",
      "metadata": {
        "id": "7d0580a5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "mom5nRqivEiR",
      "metadata": {
        "id": "mom5nRqivEiR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "b0756591",
      "metadata": {
        "id": "b0756591"
      },
      "outputs": [],
      "source": [
        "def load_array(filename, task):\n",
        "    datapoint = np.load(filename)\n",
        "    if task == 'task 1':\n",
        "        initial_state = datapoint['initial_state']\n",
        "        terminal_state = datapoint['terminal_state']\n",
        "        return initial_state, terminal_state\n",
        "    elif task == 'task 2' or task == 'task 3':\n",
        "        whole_trajectory = datapoint['trajectory']\n",
        "        # change shape: (num_bodies, attributes, time) ->  num_bodies, time, attributes\n",
        "        whole_trajectory = np.swapaxes(whole_trajectory, 1, 2)\n",
        "        initial_state = whole_trajectory[:, 0]\n",
        "        target = whole_trajectory[:, 1:, 1:]  # drop the first timepoint (second dim) and mass (last dim) for the prediction task\n",
        "        return initial_state, target\n",
        "    else:\n",
        "        raise NotImplementedError(\"'task' argument should be 'task 1', 'task 2' or 'task 3'!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "bb77a4be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb77a4be",
        "outputId": "8e8ed072-43b3-4d03-a192-1abcd6a581e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape of initial state (model input): (8, 5)\n",
            "shape of terminal state (to be predicted by model): (8, 2)\n",
            "The initial x-coordinate of the body with index 2 in this trajectory was -5.159721083543527\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This cell gives an example of loading a datapoint with numpy for task 1.\n",
        "\n",
        "The arrays returned by the function are structures as follows:\n",
        "initial_state: shape (n_bodies, [mass, x, y, v_x, v_y])\n",
        "terminal_state: shape (n_bodies, [x, y])\n",
        "\n",
        "\"\"\"\n",
        "example = load_array('data/task 1/train/trajectory_0.npz', task='task 1')\n",
        "\n",
        "initial_state, terminal_state = example\n",
        "print(f'shape of initial state (model input): {initial_state.shape}')\n",
        "print(f'shape of terminal state (to be predicted by model): {terminal_state.shape}')\n",
        "\n",
        "body_idx = 2\n",
        "print(f'The initial x-coordinate of the body with index {body_idx} in this trajectory was {initial_state[body_idx, 1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "1c3ea4cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c3ea4cb",
        "outputId": "311aff9d-a944-4c61-8157-7d51de265d6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape of initial state (model input): (8, 5)\n",
            "shape of terminal state (to be predicted by model): (8, 49, 4)\n",
            "The y-coordinate of the body with index 2 at time with index 30 in remaining_trajectory was -0.3861544940435097\n",
            "the shape of the input of a test data example is (8, 5)\n",
            "the shape of the target of a test data example is (8, 49, 4)\n",
            "values of the test data example at time 30:\n",
            " [[-5.85725792 -5.394571           nan         nan]\n",
            " [-6.03781257 -5.72445953         nan         nan]\n",
            " [-0.90623054 -6.93416278         nan         nan]\n",
            " [ 2.83149339 -7.50100819         nan         nan]\n",
            " [-2.85586881  1.77667501         nan         nan]\n",
            " [ 4.04424526  4.00563603         nan         nan]\n",
            " [-5.24887713 -4.83081005         nan         nan]\n",
            " [-5.81391023 -5.1109838          nan         nan]]\n",
            "note: velocity values are unobserved (NaNs) in the test data!\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This cell gives an example of loading a datapoint with numpy for task 2 / 3.\n",
        "\n",
        "The arrays returned by the function are structures as follows:\n",
        "initial_state: shape (n_bodies, [mass, x, y, v_x, v_y])\n",
        "remaining_trajectory: shape (n_bodies, time, [x, y, v_x, v_y])\n",
        "\n",
        "Note that for this task, you are asked to evaluate performance only with regard to the predictions of the positions (x and y).\n",
        "If you use the velocity of the remaining trajectory for training,\n",
        "this use should be purely auxiliary for the goal of predicting the positions [x,y] over time.\n",
        "While testing performance of your model on the test set, you do not have access to v_x and v_y of the remaining trajectory.\n",
        "\"\"\"\n",
        "\n",
        "example = load_array('data/task 2_3/train/trajectory_0.npz', task='task 2')\n",
        "\n",
        "initial_state, remaining_trajectory = example\n",
        "print(f'shape of initial state (model input): {initial_state.shape}')\n",
        "print(f'shape of terminal state (to be predicted by model): {remaining_trajectory.shape}')\n",
        "\n",
        "body_idx = 2\n",
        "time_idx = 30\n",
        "print(f'The y-coordinate of the body with index {body_idx} at time with index {time_idx} in remaining_trajectory was {remaining_trajectory[body_idx, time_idx, 1]}')\n",
        "\n",
        "test_example = load_array('data/task 2_3/test/trajectory_900.npz', task='task 3')\n",
        "test_initial_state, test_remaining_trajectory = test_example\n",
        "print(f'the shape of the input of a test data example is {test_initial_state.shape}')\n",
        "print(f'the shape of the target of a test data example is {test_remaining_trajectory.shape}')\n",
        "print(f'values of the test data example at time {time_idx}:\\n {test_remaining_trajectory[:, time_idx]}')\n",
        "print('note: velocity values are unobserved (NaNs) in the test data!')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "059b633c",
      "metadata": {
        "id": "059b633c"
      },
      "source": [
        "# Data Handling and Preprocessing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "La_2PbAqfEXj",
      "metadata": {
        "id": "La_2PbAqfEXj"
      },
      "source": [
        "First, let's import the data and make variables for the train and test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "0576f430",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape:  torch.Size([900, 9, 5])\n",
            "y_train shape:  torch.Size([900, 9, 49, 4])\n",
            "X_test shape:  torch.Size([100, 9, 5])\n",
            "y_test shape:  torch.Size([100, 9, 49, 4])\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "\n",
        "class ImportData(Dataset):\n",
        "    def __init__(self, folder_path):\n",
        "        self.folder_path = folder_path\n",
        "        self.file_list = sorted(os.listdir(folder_path))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        file_name = self.file_list[index]\n",
        "        file_path = os.path.join(self.folder_path, file_name)\n",
        "        data, label = load_array(file_path, task='task 2')\n",
        "        return data, label\n",
        "\n",
        "# Create an instance of the custom dataset class with the folder path\n",
        "train_import = ImportData('data/task 2_3/train/')\n",
        "test_import = ImportData('data/task 2_3/test/')\n",
        "\n",
        "X_train_import = []\n",
        "y_train_import = []\n",
        "X_test_import = []\n",
        "y_test_import = []\n",
        "\n",
        "# Iterate through the train_dataset to extract data and labels\n",
        "for data, label in train_import:\n",
        "    X_train_import.append(data)\n",
        "    y_train_import.append(label)\n",
        "\n",
        "for data, label in test_import:\n",
        "    X_test_import.append(data)\n",
        "    y_test_import.append(label)\n",
        "\n",
        "max_length = 9\n",
        "max_seq = 49\n",
        "\n",
        "# Pad the data samples with zeros to have the same shape\n",
        "X_train_padded = []\n",
        "for data in X_train_import:\n",
        "    pad_width = max_length - data.shape[0]\n",
        "    padded_data = np.pad(data, ((0, pad_width), (0, 0)), mode='constant')\n",
        "    X_train_padded.append(padded_data)\n",
        "\n",
        "y_train_padded = []\n",
        "for label in y_train_import:\n",
        "    pad_width = max_length - label.shape[0]\n",
        "    pad_length = max_seq - label.shape[1]\n",
        "    padded_label = np.pad(label, ((0, pad_width), (0, pad_length), (0,0)), mode='constant')\n",
        "    y_train_padded.append(padded_label)\n",
        "\n",
        "X_test_padded = []\n",
        "for data in X_test_import:\n",
        "    pad_width = max_length - data.shape[0]\n",
        "    padded_data = np.pad(data, ((0, pad_width), (0, 0)), mode='constant')\n",
        "    X_test_padded.append(padded_data)\n",
        "\n",
        "y_test_padded = []\n",
        "for label in y_test_import:\n",
        "    pad_width = max_length - label.shape[0]\n",
        "    pad_length = max_seq - label.shape[1]\n",
        "    padded_label = np.pad(label, ((0, pad_width), (0, pad_length), (0,0)), mode='constant')\n",
        "    y_test_padded.append(padded_label)\n",
        "\n",
        "# Convert the padded data and labels to tensors\n",
        "X_train = torch.tensor(np.array(X_train_padded))\n",
        "y_train = torch.tensor(np.array(y_train_padded))\n",
        "X_test = torch.tensor(np.array(X_test_padded))\n",
        "y_test = torch.tensor(np.array(y_test_padded))\n",
        "\n",
        "# Print the shape of X_train and the first label in y_train\n",
        "print(\"X_train shape: \", X_train.shape)\n",
        "print(\"y_train shape: \", y_train.shape)\n",
        "print(\"X_test shape: \", X_test.shape)\n",
        "print(\"y_test shape: \", y_test.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "18b2874d",
      "metadata": {
        "id": "18b2874d"
      },
      "source": [
        "# Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "29b2cec2",
      "metadata": {},
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size=9*5, hidden_size=128, num_layers=49, batch_first=True)\n",
        "        self.linear = nn.Linear(128, 45)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output, (h_n, c_n) = self.lstm(x)\n",
        "        output, (h_n, c_n) = self.linear(output), self.linear(h_n), self.linear(c_n)\n",
        "        return output, (h_n, c_n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "44e2304f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 45])"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[0].flatten().unsqueeze(0).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "4bb9af48",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (lstm): LSTM(5, 64, num_layers=49, batch_first=True)\n",
              "  (linear): Linear(in_features=64, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "5b66c726",
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[117], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[39m=\u001b[39m LSTM()\n\u001b[1;32m----> 2\u001b[0m output, (h_n, c_n) \u001b[39m=\u001b[39m model(X_train[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mflatten()\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mfloat())\n\u001b[0;32m      3\u001b[0m output\u001b[39m.\u001b[39mshape, c_n\u001b[39m.\u001b[39mshape, h_n\u001b[39m.\u001b[39mshape\n",
            "File \u001b[1;32mc:\\Users\\20174216\\OneDrive - TU Eindhoven\\Documents\\1. TUe MSc DSAI\\Q4\\2AMM10 - Deep Learning\\tue-deeplearning\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "Cell \u001b[1;32mIn[113], line 9\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m      8\u001b[0m     output, (h_n, c_n) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(x)\n\u001b[1;32m----> 9\u001b[0m     output, (h_n, c_n) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear(output), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear(h_n), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear(c_n)\n\u001b[0;32m     10\u001b[0m     \u001b[39mreturn\u001b[39;00m output, (h_n, c_n)\n",
            "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ],
      "source": [
        "model = LSTM()\n",
        "output, (h_n, c_n) = model(X_train[0].flatten().unsqueeze(0).float())\n",
        "output.shape, c_n.shape, h_n.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "dea70d73",
      "metadata": {
        "id": "dea70d73"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "35e87754",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\20174216\\OneDrive - TU Eindhoven\\Documents\\1. TUe MSc DSAI\\Q4\\2AMM10 - Deep Learning\\tue-deeplearning\\.venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([1, 9, 2])) that is different to the input size (torch.Size([1, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 2",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m     18\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m---> 19\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     20\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     21\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
            "File \u001b[1;32mc:\\Users\\20174216\\OneDrive - TU Eindhoven\\Documents\\1. TUe MSc DSAI\\Q4\\2AMM10 - Deep Learning\\tue-deeplearning\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\20174216\\OneDrive - TU Eindhoven\\Documents\\1. TUe MSc DSAI\\Q4\\2AMM10 - Deep Learning\\tue-deeplearning\\.venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 536\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmse_loss(\u001b[39minput\u001b[39;49m, target, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
            "File \u001b[1;32mc:\\Users\\20174216\\OneDrive - TU Eindhoven\\Documents\\1. TUe MSc DSAI\\Q4\\2AMM10 - Deep Learning\\tue-deeplearning\\.venv\\lib\\site-packages\\torch\\nn\\functional.py:3294\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3291\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3292\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3294\u001b[0m expanded_input, expanded_target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbroadcast_tensors(\u001b[39minput\u001b[39;49m, target)\n\u001b[0;32m   3295\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[39m.\u001b[39mget_enum(reduction))\n",
            "File \u001b[1;32mc:\\Users\\20174216\\OneDrive - TU Eindhoven\\Documents\\1. TUe MSc DSAI\\Q4\\2AMM10 - Deep Learning\\tue-deeplearning\\.venv\\lib\\site-packages\\torch\\functional.py:74\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function(tensors):\n\u001b[0;32m     73\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[39m*\u001b[39mtensors)\n\u001b[1;32m---> 74\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49mbroadcast_tensors(tensors)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 2"
          ]
        }
      ],
      "source": [
        "model = LSTM()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Set the number of epochs\n",
        "num_epochs = 10\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "\n",
        "    # Iterate over the batches in the training data loader\n",
        "    for inputs, labels in train_dataloader:\n",
        "        inputs = inputs.flatten().float()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        labels = labels.flatten().float()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print the training loss for each epoch\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {loss.item()}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "f66e105c",
      "metadata": {},
      "source": [
        "## TASK 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "b634e248",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 1.5297,  4.8351, -2.7770,  0.1329, -1.1525,  1.1972,  5.6298, -5.9625,\n",
            "        -0.0313, -1.4090,  3.1135,  5.6200, -7.4318, -0.0117, -0.0723,  4.9907,\n",
            "        -0.3072, -5.4653, -0.0700, -0.1166,  2.0705, -3.1344,  1.5606,  0.9900,\n",
            "         0.6839,  1.7183, -1.4192,  1.2388, -1.0650,  1.6533,  0.0000,  0.0000,\n",
            "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000], dtype=torch.float64)\n",
            "tensor([  4.1023, -10.2635,   4.8284,  -6.8794,   2.1943,  -7.7186,   1.6086,\n",
            "         -6.1160,  -0.8597,   9.4192,  -2.3063,   1.4827,   0.0000,   0.0000,\n",
            "          0.0000,   0.0000,   0.0000,   0.0000], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "for inputs, labels in train_dataloader:\n",
        "    if i<1:\n",
        "        print(inputs.flatten())\n",
        "        print(labels.flatten())\n",
        "        i+=1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
